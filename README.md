# llm-proxy

Using litellm to proxy various LLM models into a unified OpenAI API format for easier use.

```bash
make echo # echo env variables
make install # install dependencies
make run # run the proxy
make test_proxy # test the proxy
```
